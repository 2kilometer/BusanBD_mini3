{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 긍부정 판별을 위한 KoBERT 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17536,
     "status": "ok",
     "timestamp": 1692828663969,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "ty83NT9Srd3O",
    "outputId": "acb0a5c1-96ae-4010-cfc3-0920fdf5cff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.0\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n"
     ]
    }
   ],
   "source": [
    "# 필요 모듈 설치\n",
    "\n",
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18437,
     "status": "ok",
     "timestamp": 1692828682403,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "uSyZym1brOQj",
    "outputId": "5505b23b-5447-4c4d-a545-8dc9a9a28660"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation_flax_utils.py:24: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "## 필요 모듈 import \n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import *\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sentencepiece as spm\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21948,
     "status": "ok",
     "timestamp": 1692828704347,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "ougFOG8vrWFq",
    "outputId": "1c3d2740-1288-4d38-f61b-6e2f8bfadbc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# 구글드라이브 실행\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62f9CWP7rOQm"
   },
   "outputs": [],
   "source": [
    "# 데이터 불러들이기\n",
    "\n",
    "df_train = pd.read_csv('./data/df_train_eda_total_len_less_6_filtered.csv',encoding='utf-8-sig')\n",
    "df_test = pd.read_csv('./data/df_test_eda_total_len_less_6_filtered.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAetjzkoMdfs"
   },
   "outputs": [],
   "source": [
    "## 중복 row 제거\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_test = df_test.drop_duplicates()\n",
    "df_no_star = df_no_star.drop_duplicates()\n",
    "\n",
    "# review NaN인 row drop\n",
    "df_train = df_train.dropna(subset='review_content')\n",
    "df_test = df_test.dropna(subset='review_content')\n",
    "df_no_star = df_no_star[df_no_star['review_content'].notnull()]\n",
    "\n",
    "# reset index\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "df_no_star.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# 변수명 수정\n",
    "train, test = df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1692830421769,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "RUCKlKzFrOQp",
    "outputId": "c319e193-9e79-4cc5-9cc2-2e3c6184cd3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0    38357\n",
       " 0.0     4100\n",
       " Name: rating, dtype: int64,\n",
       " 1.0    153426\n",
       " 0.0    147591\n",
       " Name: rating, dtype: int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value count 확인\n",
    "\n",
    "test['rating'].value_counts(),train['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncnGXYP5rOQr"
   },
   "source": [
    "## 버트 인풋 만들기\n",
    "\n",
    "한글 데이터를 분석하려면, 100개가 넘는 언어에 대해 훈련된 버트를 사용해야 합니다.\n",
    "이번에는 한국어 데이터로 훈련되었고, SKT에서 만든 KoBERT를 사용하도록 하겠습니다.\n",
    "모델을 로드하기에 앞서, 토크나이저를 불러오도록 하겠습니다.\n",
    "huggingface에서는 아주 쉽게 토크나이저를 불러올 수 있습니다.\n",
    "https://github.com/monologg/KoBERT-NER 에서 kobert를 tokenize 할 수 있는 코드를 가져왔습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVOcxoIfrOQs"
   },
   "outputs": [],
   "source": [
    "# KoBERT 토크나이저를 활용\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import unicodedata\n",
    "from shutil import copyfile\n",
    "\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n",
    "                     \"vocab_txt\": \"vocab.txt\"}\n",
    "\n",
    "PRETRAINED_VOCAB_FILES_MAP = {\n",
    "    \"vocab_file\": {\n",
    "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n",
    "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n",
    "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n",
    "    },\n",
    "    \"vocab_txt\": {\n",
    "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n",
    "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n",
    "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n",
    "    }\n",
    "}\n",
    "\n",
    "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n",
    "    \"monologg/kobert\": 512,\n",
    "    \"monologg/kobert-lm\": 512,\n",
    "    \"monologg/distilkobert\": 512\n",
    "}\n",
    "\n",
    "PRETRAINED_INIT_CONFIGURATION = {\n",
    "    \"monologg/kobert\": {\"do_lower_case\": False},\n",
    "    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n",
    "    \"monologg/distilkobert\": {\"do_lower_case\": False}\n",
    "}\n",
    "\n",
    "SPIECE_UNDERLINE = u'▁'\n",
    "\n",
    "\n",
    "class KoBertTokenizer(PreTrainedTokenizer):\n",
    "    \"\"\"\n",
    "        SentencePiece based tokenizer. Peculiarities:\n",
    "            - requires `SentencePiece `_\n",
    "    \"\"\"\n",
    "    vocab_files_names = VOCAB_FILES_NAMES\n",
    "    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n",
    "    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n",
    "    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_file,\n",
    "            vocab_txt,\n",
    "            do_lower_case=False,\n",
    "            remove_space=True,\n",
    "            keep_accents=False,\n",
    "            unk_token=\"[UNK]\",\n",
    "            sep_token=\"[SEP]\",\n",
    "            pad_token=\"[PAD]\",\n",
    "            cls_token=\"[CLS]\",\n",
    "            mask_token=\"[MASK]\",\n",
    "            **kwargs):\n",
    "        super().__init__(\n",
    "            unk_token=unk_token,\n",
    "            sep_token=sep_token,\n",
    "            pad_token=pad_token,\n",
    "            cls_token=cls_token,\n",
    "            mask_token=mask_token,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # Build vocab\n",
    "        self.token2idx = dict()\n",
    "        self.idx2token = []\n",
    "        with open(vocab_txt, 'r', encoding='utf-8') as f:\n",
    "            for idx, token in enumerate(f):\n",
    "                token = token.strip()\n",
    "                self.token2idx[token] = idx\n",
    "                self.idx2token.append(token)\n",
    "\n",
    "        try:\n",
    "            import sentencepiece as spm\n",
    "        except ImportError:\n",
    "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
    "                           \"pip install sentencepiece\")\n",
    "\n",
    "        self.do_lower_case = do_lower_case\n",
    "        self.remove_space = remove_space\n",
    "        self.keep_accents = keep_accents\n",
    "        self.vocab_file = vocab_file\n",
    "        self.vocab_txt = vocab_txt\n",
    "\n",
    "        self.sp_model = spm.SentencePieceProcessor()\n",
    "        self.sp_model.Load(vocab_file)\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.idx2token)\n",
    "\n",
    "    def get_vocab(self):\n",
    "        return dict(self.token2idx, **self.added_tokens_encoder)\n",
    "\n",
    "    def __getstate__(self):\n",
    "        state = self.__dict__.copy()\n",
    "        state[\"sp_model\"] = None\n",
    "        return state\n",
    "\n",
    "    def __setstate__(self, d):\n",
    "        self.__dict__ = d\n",
    "        try:\n",
    "            import sentencepiece as spm\n",
    "        except ImportError:\n",
    "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
    "                           \"pip install sentencepiece\")\n",
    "        self.sp_model = spm.SentencePieceProcessor()\n",
    "        self.sp_model.Load(self.vocab_file)\n",
    "\n",
    "    def preprocess_text(self, inputs):\n",
    "        if self.remove_space:\n",
    "            outputs = \" \".join(inputs.strip().split())\n",
    "        else:\n",
    "            outputs = inputs\n",
    "        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n",
    "\n",
    "        if not self.keep_accents:\n",
    "            outputs = unicodedata.normalize('NFKD', outputs)\n",
    "            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n",
    "        if self.do_lower_case:\n",
    "            outputs = outputs.lower()\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def _tokenize(self, text, return_unicode=True, sample=False):\n",
    "        \"\"\" Tokenize a string. \"\"\"\n",
    "        text = self.preprocess_text(text)\n",
    "\n",
    "        if not sample:\n",
    "            pieces = self.sp_model.EncodeAsPieces(text)\n",
    "        else:\n",
    "            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n",
    "        new_pieces = []\n",
    "        for piece in pieces:\n",
    "            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n",
    "                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n",
    "                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n",
    "                    if len(cur_pieces[0]) == 1:\n",
    "                        cur_pieces = cur_pieces[1:]\n",
    "                    else:\n",
    "                        cur_pieces[0] = cur_pieces[0][1:]\n",
    "                cur_pieces.append(piece[-1])\n",
    "                new_pieces.extend(cur_pieces)\n",
    "            else:\n",
    "                new_pieces.append(piece)\n",
    "\n",
    "        return new_pieces\n",
    "\n",
    "    def _convert_token_to_id(self, token):\n",
    "        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n",
    "        return self.token2idx.get(token, self.token2idx[self.unk_token])\n",
    "\n",
    "    def _convert_id_to_token(self, index, return_unicode=True):\n",
    "        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n",
    "        return self.idx2token[index]\n",
    "\n",
    "    def convert_tokens_to_string(self, tokens):\n",
    "        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n",
    "        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n",
    "        return out_string\n",
    "\n",
    "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "        \"\"\"\n",
    "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n",
    "        by concatenating and adding special tokens.\n",
    "        A KoBERT sequence has the following format:\n",
    "            single sequence: [CLS] X [SEP]\n",
    "            pair of sequences: [CLS] A [SEP] B [SEP]\n",
    "        \"\"\"\n",
    "        if token_ids_1 is None:\n",
    "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
    "        cls = [self.cls_token_id]\n",
    "        sep = [self.sep_token_id]\n",
    "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
    "\n",
    "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n",
    "        \"\"\"\n",
    "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n",
    "        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n",
    "        Args:\n",
    "            token_ids_0: list of ids (must not contain special tokens)\n",
    "            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n",
    "                for sequence pairs\n",
    "            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n",
    "                special tokens for the model\n",
    "        Returns:\n",
    "            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n",
    "        \"\"\"\n",
    "\n",
    "        if already_has_special_tokens:\n",
    "            if token_ids_1 is not None:\n",
    "                raise ValueError(\n",
    "                    \"You should not supply a second sequence if the provided sequence of \"\n",
    "                    \"ids is already formated with special tokens for the model.\"\n",
    "                )\n",
    "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n",
    "\n",
    "        if token_ids_1 is not None:\n",
    "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
    "        return [1] + ([0] * len(token_ids_0)) + [1]\n",
    "\n",
    "    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n",
    "        \"\"\"\n",
    "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n",
    "        A KoBERT sequence pair mask has the following format:\n",
    "        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
    "        | first sequence    | second sequence\n",
    "        if token_ids_1 is None, only returns the first portion of the mask (0's).\n",
    "        \"\"\"\n",
    "        sep = [self.sep_token_id]\n",
    "        cls = [self.cls_token_id]\n",
    "        if token_ids_1 is None:\n",
    "            return len(cls + token_ids_0 + sep) * [0]\n",
    "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n",
    "\n",
    "    def save_vocabulary(self, save_directory):\n",
    "        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n",
    "            to a directory.\n",
    "        \"\"\"\n",
    "        if not os.path.isdir(save_directory):\n",
    "            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n",
    "            return\n",
    "\n",
    "        # 1. Save sentencepiece model\n",
    "        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n",
    "\n",
    "        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n",
    "            copyfile(self.vocab_file, out_vocab_model)\n",
    "\n",
    "        # 2. Save vocab.txt\n",
    "        index = 0\n",
    "        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n",
    "        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n",
    "            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n",
    "                if index != token_index:\n",
    "                    logger.warning(\n",
    "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
    "                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n",
    "                    )\n",
    "                    index = token_index\n",
    "                writer.write(token + \"\\n\")\n",
    "                index += 1\n",
    "\n",
    "        return out_vocab_model, out_vocab_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1692830423029,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "v2QwDpGHrOQt",
    "outputId": "23bf6c3f-23af-4832-9e6c-284af5946fb0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file tokenizer_78b3253a26.model from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/30941062c0f3dde73b246468f449f2448c7694bc/tokenizer_78b3253a26.model\n",
      "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/30941062c0f3dde73b246468f449f2448c7694bc/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/30941062c0f3dde73b246468f449f2448c7694bc/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/30941062c0f3dde73b246468f449f2448c7694bc/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"monologg/kobert\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.32.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8002\n",
      "}\n",
      "\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'KoBertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "# monologg/kobert 모델을 사용하여 KoBertTokenizer 객체를 생성한다.\n",
    "\n",
    "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75980,
     "status": "ok",
     "timestamp": 1692830499002,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "9ewi3TYprOQt",
    "outputId": "871d88f5-1dcf-4947-86ac-180eef6b03e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301017/301017 [01:11<00:00, 4195.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 변환을 위한 함수\n",
    "\n",
    "def convert_data(data_df):\n",
    "    global tokenizer\n",
    "\n",
    "    SEQ_LEN = 64  # SEQ_LEN : 버트에 들어갈 인풋의 길이\n",
    "\n",
    "    tokens, masks, segments, targets = [], [], [], []\n",
    "\n",
    "    for i in tqdm(range(len(data_df))):\n",
    "        # token : 문장을 토큰화함\n",
    "        token = tokenizer.encode(\n",
    "            data_df[DATA_COLUMN][i], truncation=True, padding='max_length', max_length=SEQ_LEN)\n",
    "\n",
    "        # 마스크는 토큰화한 문장에서 패딩이 아닌 부분은 1, 패딩인 부분은 0으로 통일\n",
    "        num_zeros = token.count(0)\n",
    "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n",
    "\n",
    "        # 문장의 전후관계를 구분해주는 세그먼트는 문장이 1개밖에 없으므로 모두 0\n",
    "        segment = [0]*SEQ_LEN\n",
    "\n",
    "        # 버트 인풋으로 들어가는 token, mask, segment를 tokens, segments에 각각 저장\n",
    "        tokens.append(token)\n",
    "        masks.append(mask)\n",
    "        segments.append(segment)\n",
    "\n",
    "        # 정답(긍정 : 1 부정 0)을 targets 변수에 저장해 줌\n",
    "        targets.append(data_df[LABEL_COLUMN][i])\n",
    "\n",
    "    # tokens, masks, segments, 정답 변수 targets를 numpy array로 지정\n",
    "    tokens = np.array(tokens)\n",
    "    masks = np.array(masks)\n",
    "    segments = np.array(segments)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    return [tokens, masks, segments], targets\n",
    "\n",
    "# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\n",
    "\n",
    "\n",
    "def load_data(pandas_dataframe):\n",
    "    data_df = pandas_dataframe\n",
    "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
    "    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\n",
    "    data_x, data_y = convert_data(data_df)\n",
    "    return data_x, data_y\n",
    "\n",
    "\n",
    "SEQ_LEN = 64\n",
    "BATCH_SIZE = 32\n",
    "# 긍부정 문장을 포함하고 있는 칼럼\n",
    "DATA_COLUMN = \"review_content\"\n",
    "# 긍정인지 부정인지를 (1=긍정,0=부정) 포함하고 있는 칼럼\n",
    "LABEL_COLUMN = \"rating\"\n",
    "\n",
    "# train 데이터를 버트 인풋에 맞게 변환\n",
    "train_x, train_y = load_data(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10007,
     "status": "ok",
     "timestamp": 1692830509004,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "XM-SwFNfrOQt",
    "outputId": "6445a29e-5c4c-4d8d-a569-6c5649dc3d3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42457/42457 [00:09<00:00, 4466.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# 훈련 성능을 검증한 test 데이터를 버트 인풋에 맞게 변환\n",
    "test_x, test_y = load_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NN3xsTcrOQu"
   },
   "source": [
    "## 버트를 활용한 감성분석 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3355,
     "status": "ok",
     "timestamp": 1692830512344,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "5JYPjw05rOQu",
    "outputId": "076a364b-83bf-47b4-ea16-a39f95647e2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/30941062c0f3dde73b246468f449f2448c7694bc/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.32.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8002\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/30941062c0f3dde73b246468f449f2448c7694bc/pytorch_model.bin\n",
      "Loading PyTorch weights from /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/30941062c0f3dde73b246468f449f2448c7694bc/pytorch_model.bin\n",
      "PyTorch checkpoint contains 92,186,880 parameters\n",
      "Loaded 92,186,880 parameters in the TF 2.0 model.\n",
      "All PyTorch model weights were used when initializing TFBertModel.\n",
      "\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertModel.from_pretrained(\n",
    "    \"monologg/kobert\", from_pt=True)  # monologg/kobert 모델 불러오기\n",
    "\n",
    "\n",
    "# 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\n",
    "token_inputs = tf.keras.layers.Input(\n",
    "    (SEQ_LEN,), dtype=tf.int32, name='input_word_ids')  # 입력 토큰 정의\n",
    "mask_inputs = tf.keras.layers.Input(\n",
    "    (SEQ_LEN,), dtype=tf.int32, name='input_masks')  # 입력 마스크 정의\n",
    "segment_inputs = tf.keras.layers.Input(\n",
    "    (SEQ_LEN,), dtype=tf.int32, name='input_segment')  # 입력 세그먼트 정의\n",
    "\n",
    "\n",
    "# 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\n",
    "bert_outputs = model(\n",
    "    [token_inputs, mask_inputs, segment_inputs])  # bert 모델의 출력 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFNpVqobrOQu"
   },
   "outputs": [],
   "source": [
    "# fine-tuning을 적용을 위해 index 1로 적용\n",
    "\n",
    "bert_outputs = bert_outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1692830512345,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "_K5Nl-RcCBO8",
    "outputId": "5c304f7e-9249-4a1c-e186-3b7e9f9363a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(768,) dtype=float32 (created by layer 'tf.__operators__.getitem_1')>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1692830516393,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "naE-8a7LrOQu",
    "outputId": "ef112748-b1e3-4168-98b5-dc7db4cb4a21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/optimizers/rectified_adam.py:121: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Rectified Adam 옵티마이저 생성\n",
    "# Adam보다 초기 학습에서의 강점\n",
    "\n",
    "opt = tfa.optimizers.RectifiedAdam(\n",
    "    lr=5.0e-5,  # learning rate 설정\n",
    "    total_steps=2344*2,  # 총 스텝 수 설정\n",
    "    warmup_proportion=0.1,  # warmup 비율 설정\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Kr3pl8ErOQu"
   },
   "outputs": [],
   "source": [
    "# fine-tuning을 위한 모델링 설정\n",
    "\n",
    "sentiment_drop = tf.keras.layers.Dropout(\n",
    "    0.5)(bert_outputs)  # BERT 출력값에 드롭아웃 적용\n",
    "\n",
    "sentiment_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(\n",
    "    stddev=0.02))(sentiment_drop)  # 드롭아웃 적용된 BERT 출력값에 fully connected layer 적용\n",
    "\n",
    "sentiment_model = tf.keras.Model(\n",
    "    [token_inputs, mask_inputs, segment_inputs], sentiment_first)  # 입력값과 출력값을 지정하여 모델 생성\n",
    "    \n",
    "sentiment_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics=[\n",
    "                        'acc'])  # 모델 컴파일, optimizer는 Adam, loss는 binary crossentropy, 평가 지표는 accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 652,
     "status": "ok",
     "timestamp": 1692830517038,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "d3tsfXIOjB4w",
    "outputId": "d42cfb33-0e84-4c22-c49e-5382a332740e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " input_masks (InputLayer)       [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " input_segment (InputLayer)     [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  92186880    ['input_word_ids[0][0]',         \n",
      "                                thPoolingAndCrossAt               'input_masks[0][0]',            \n",
      "                                tentions(last_hidde               'input_segment[0][0]']          \n",
      "                                n_state=(None, 64,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dropout_75 (Dropout)           (None, 768)          0           ['tf_bert_model_1[0][1]']        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            769         ['dropout_75[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 92,187,649\n",
      "Trainable params: 92,187,649\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model summary 확인\n",
    "\n",
    "sentiment_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5490392,
     "status": "ok",
     "timestamp": 1692836007425,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "TU_l-ySCrOQv",
    "outputId": "a8a48346-a24f-4cfa-93a4-e79cae283a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n",
      "Epoch 1/10\n",
      "4704/4704 [==============================] - 1397s 292ms/step - loss: 0.2696 - acc: 0.8829 - val_loss: 0.1865 - val_acc: 0.9288\n",
      "Epoch 2/10\n",
      "4704/4704 [==============================] - 1367s 291ms/step - loss: 0.1537 - acc: 0.9423 - val_loss: 0.1865 - val_acc: 0.9288\n",
      "Epoch 3/10\n",
      "4704/4704 [==============================] - 1364s 290ms/step - loss: 0.1533 - acc: 0.9423 - val_loss: 0.1865 - val_acc: 0.9288\n",
      "Epoch 4/10\n",
      "4704/4704 [==============================] - 1361s 289ms/step - loss: 0.1533 - acc: 0.9422 - val_loss: 0.1865 - val_acc: 0.9288\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "# GPU를 사용하기 위해 런타임 유형을 GPU로 변경\n",
    "\n",
    "es=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=3)\n",
    "\n",
    "\n",
    "# GPU를 사용하기 위한 설정\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "# 모델 학습\n",
    "with tf.device('/device:GPU:0'):\n",
    "  history = sentiment_model.fit(train_x, train_y, epochs=10, shuffle=True,\n",
    "                      batch_size=64,callbacks=es, validation_data=(test_x, test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsV2YmgwyBmd"
   },
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxZPpbKFrOQv"
   },
   "outputs": [],
   "source": [
    "# 예측에 필요한 함수 적용\n",
    "\n",
    "def predict_convert_data(data_df):\n",
    "    global tokenizer\n",
    "    tokens, masks, segments = [], [], []\n",
    "\n",
    "    for i in tqdm(range(len(data_df))):  # 데이터프레임의 길이만큼 반복문 실행\n",
    "\n",
    "        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN,\n",
    "                                 truncation=True, padding='max_length')  # 문장을 토큰화하여 인코딩\n",
    "        num_zeros = token.count(0)  # 0의 개수를 세어 num_zeros에 저장\n",
    "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros  # mask 생성\n",
    "        segment = [0]*SEQ_LEN  # segment 생성\n",
    "\n",
    "        tokens.append(token)  # tokens 리스트에 token 추가\n",
    "        segments.append(segment)  # segments 리스트에 segment 추가\n",
    "        masks.append(mask)  # masks 리스트에 mask 추가\n",
    "\n",
    "    tokens = np.array(tokens)  # tokens 리스트를 numpy 배열로 변환\n",
    "    masks = np.array(masks)  # masks 리스트를 numpy 배열로 변환\n",
    "    segments = np.array(segments)  # segments 리스트를 numpy 배열로 변환\n",
    "    return [tokens, masks, segments]\n",
    "\n",
    "# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\n",
    "\n",
    "\n",
    "def predict_load_data(pandas_dataframe):\n",
    "    data_df = pandas_dataframe\n",
    "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(\n",
    "        str)  # 데이터프레임의 DATA_COLUMN 열을 문자열로 변환\n",
    "    data_x = predict_convert_data(data_df)  # convert_data 함수를 이용하여 데이터 전처리\n",
    "    return data_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9805,
     "status": "ok",
     "timestamp": 1692836017221,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "v3fiVKFErOQv",
    "outputId": "b12f6d40-f41b-40d0-8eb4-70c1987e6c20"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42457/42457 [00:09<00:00, 4652.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 변환\n",
    "\n",
    "test_set = predict_load_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78503,
     "status": "ok",
     "timestamp": 1692836095721,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "I2LbBlhRrOQv",
    "outputId": "cd8f3f5c-1616-4cec-ef31-18f6973778fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1327/1327 [==============================] - 78s 56ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "\n",
    "preds = sentiment_model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1692836095723,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "Ev7_H45RrOQw",
    "outputId": "3032ad39-27d7-43cb-8596-4dd8983c9588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.80      0.68      4100\n",
      "           1       0.98      0.94      0.96     38357\n",
      "\n",
      "    accuracy                           0.93     42457\n",
      "   macro avg       0.79      0.87      0.82     42457\n",
      "weighted avg       0.94      0.93      0.93     42457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification_report 출력하여 확인\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_true = test['rating']\n",
    "# F1 Score 확인\n",
    "print(classification_report(y_true, np.round(preds,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 486,
     "status": "ok",
     "timestamp": 1692836336656,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "MPLYXWX8bA1h",
    "outputId": "64167e4c-c5e0-42aa-8f3c-566c89e6b427"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss와 accuracy를 시각화\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(history.history['acc'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_acc'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJIP3B8frOQx"
   },
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "\n",
    "sentiment_model.save_weights(\"./판별기/ckpt_eda_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bu5nwrkNyBme"
   },
   "source": [
    "## 생성 모델로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjfG7EpXrOQw"
   },
   "outputs": [],
   "source": [
    "import logging  # logging 모듈을 import 합니다.\n",
    "tf.get_logger().setLevel(logging.ERROR)  # tensorflow의 logger를 ERROR 레벨로 설정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7X5Vt66rOQx"
   },
   "outputs": [],
   "source": [
    "\n",
    "def sentence_convert_data(data):\n",
    "    global tokenizer\n",
    "    tokens, masks, segments = [], [], []\n",
    "    token = tokenizer.encode(data, max_length=SEQ_LEN,\n",
    "                             truncation=True, padding='max_length')\n",
    "\n",
    "    num_zeros = token.count(0)  # 패딩으로 추가된 0의 개수를 세어준다.\n",
    "    mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros  # 패딩 부분은 0으로 마스킹한다.\n",
    "    segment = [0]*SEQ_LEN  # 문장의 길이만큼 segment를 0으로 채운다.\n",
    "\n",
    "    tokens.append(token)\n",
    "    segments.append(segment)\n",
    "    masks.append(mask)\n",
    "\n",
    "    tokens = np.array(tokens)\n",
    "    masks = np.array(masks)\n",
    "    segments = np.array(segments)\n",
    "    return [tokens, masks, segments]\n",
    "\n",
    "\n",
    "def review_evaluation_predict(sentence):\n",
    "    data_x = sentence_convert_data(sentence)\n",
    "    predict = sentiment_model.predict(data_x)\n",
    "    predict_value = np.ravel(predict)\n",
    "    predict_answer = np.round(predict_value, 0).item()\n",
    "\n",
    "    if predict_answer == 0:\n",
    "      # 예측값이 0일 경우, 부정적인 평가로 판단한다.\n",
    "      print(sentence)\n",
    "      print(\"(부정 확률 : %.2f) 부정적인 평가입니다.\" % (1-predict_value))\n",
    "      print('='*60)\n",
    "    # elif predict_answer == 1:\n",
    "    #   # 예측값이 1일 경우, 긍정적인 평가로 판단한다.\n",
    "    #   print(sentence)\n",
    "    #   print(\"(긍정 확률 : %.2f) 긍정적인 평가입니다.\" % predict_value)\n",
    "    #   print('='*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMQ3iUNJmpRg"
   },
   "outputs": [],
   "source": [
    "# pred 할 파일 불러들이기\n",
    "\n",
    "df_input = pd.read_csv('./data/review_concat_rating_revised_prep.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225457,
     "status": "ok",
     "timestamp": 1692837559032,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "2et44NHztgcB",
    "outputId": "ba987baf-b0b0-4ceb-b557-fca72e8c6de9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112340/112340 [00:23<00:00, 4810.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3511/3511 [==============================] - 198s 56ms/step\n"
     ]
    }
   ],
   "source": [
    "# 부른 파일 pred\n",
    "\n",
    "test_set = predict_load_data(df_input)\n",
    "preds = sentiment_model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1692837559033,
     "user": {
      "displayName": "Simon Yun",
      "userId": "11811271085600274583"
     },
     "user_tz": -540
    },
    "id": "Fm1girZ5l21i",
    "outputId": "222b6c25-cfa9-4c10-983f-213236d3f089"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2d00c59f-1bcd-4015-bb4c-1b7afff7de72\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>restaurant_name</th>\n",
       "      <th>review_content</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>visit</th>\n",
       "      <th>register</th>\n",
       "      <th>category</th>\n",
       "      <th>org_review_content</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>pred_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>전포동 베이비치크</td>\n",
       "      <td>아기자기하고 빈티지한 분위기가 좋았어요 명란청양오일파스타랑 트러플버섯크림리조또 먹었...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>1</td>\n",
       "      <td>영수증</td>\n",
       "      <td>양식</td>\n",
       "      <td>아기자기하고 빈티지한 분위기가 좋았어요ㅎㅎ 명란청양오일파스타랑 트러플버섯크림리조또 ...</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>전포동 베이비치크</td>\n",
       "      <td>입구부터 이쁜 공간이 너무 많아서 좋았던 이곳 취향저격 제대로 당해서 안으로 들어왔...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>영수증</td>\n",
       "      <td>양식</td>\n",
       "      <td>입구부터 이쁜 공간이 너무 많아서 좋았던 이곳 취향저격 제대로 당해서 안으로 들어왔...</td>\n",
       "      <td>0.997815</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>전포동 베이비치크</td>\n",
       "      <td>와    오랜만에 너무 만족스러운 식사하고 왔어여 매장 분위기도 너무 좋고 예쁘신 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-24</td>\n",
       "      <td>1</td>\n",
       "      <td>영수증</td>\n",
       "      <td>양식</td>\n",
       "      <td>와..오랜만에 너무 만족스러운 식사하고 왔어여ㅠ 매장 분위기도 너무 좋고 예쁘신 사...</td>\n",
       "      <td>0.997788</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>전포동 베이비치크</td>\n",
       "      <td>지난번에 너무 맛있게 먹고 이번에 재방문했어요   베이비치크 플레이트는 진짜 무조건...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-09</td>\n",
       "      <td>1</td>\n",
       "      <td>영수증</td>\n",
       "      <td>양식</td>\n",
       "      <td>지난번에 너무 맛있게 먹고 이번에 재방문했어요! 베이비치크 플레이트는 진짜 무조건 ...</td>\n",
       "      <td>0.997869</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>전포동 베이비치크</td>\n",
       "      <td>양 진짜 많고 너무 맛있어요 안에도 아기자기 앤티크하게 잘 꾸며져있고 감성도 맛도 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-05</td>\n",
       "      <td>1</td>\n",
       "      <td>영수증</td>\n",
       "      <td>양식</td>\n",
       "      <td>양 진짜 많고 너무 맛있어요ㅠㅠ 안에도 아기자기 앤티크하게 잘 꾸며져있고ㅠㅠㅠ 감성...</td>\n",
       "      <td>0.997817</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112335</th>\n",
       "      <td>116259</td>\n",
       "      <td>양정동 명심이족발</td>\n",
       "      <td>맛있어요</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-12-19</td>\n",
       "      <td>1</td>\n",
       "      <td>영수증</td>\n",
       "      <td>족발,보쌈</td>\n",
       "      <td>맛있어요</td>\n",
       "      <td>0.905437</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112336</th>\n",
       "      <td>116260</td>\n",
       "      <td>양정동 명심이족발</td>\n",
       "      <td>맛있고 양도 많았어요</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>2</td>\n",
       "      <td>영수증</td>\n",
       "      <td>족발,보쌈</td>\n",
       "      <td>맛있고 양도 많았어요!</td>\n",
       "      <td>0.985904</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112337</th>\n",
       "      <td>116261</td>\n",
       "      <td>양정동 명심이족발</td>\n",
       "      <td>좋아요</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>1</td>\n",
       "      <td>영수증</td>\n",
       "      <td>족발,보쌈</td>\n",
       "      <td>좋아요</td>\n",
       "      <td>0.913858</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112338</th>\n",
       "      <td>116262</td>\n",
       "      <td>양정동 명심이족발</td>\n",
       "      <td>맛있어요</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>1</td>\n",
       "      <td>영수증</td>\n",
       "      <td>족발,보쌈</td>\n",
       "      <td>맛있어요</td>\n",
       "      <td>0.905437</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112339</th>\n",
       "      <td>116263</td>\n",
       "      <td>양정동 명심이족발</td>\n",
       "      <td>좋아요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-22</td>\n",
       "      <td>1</td>\n",
       "      <td>영수증</td>\n",
       "      <td>족발,보쌈</td>\n",
       "      <td>좋아요</td>\n",
       "      <td>0.913858</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112340 rows × 11 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d00c59f-1bcd-4015-bb4c-1b7afff7de72')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-2d00c59f-1bcd-4015-bb4c-1b7afff7de72 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-2d00c59f-1bcd-4015-bb4c-1b7afff7de72');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-739078cd-e05e-465c-8ad0-d289ad3f911f\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-739078cd-e05e-465c-8ad0-d289ad3f911f')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const charts = await google.colab.kernel.invokeFunction(\n",
       "          'suggestCharts', [key], {});\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-739078cd-e05e-465c-8ad0-d289ad3f911f button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "        Unnamed: 0 restaurant_name  \\\n",
       "0                0       전포동 베이비치크   \n",
       "1                1       전포동 베이비치크   \n",
       "2                2       전포동 베이비치크   \n",
       "3                3       전포동 베이비치크   \n",
       "4                4       전포동 베이비치크   \n",
       "...            ...             ...   \n",
       "112335      116259       양정동 명심이족발   \n",
       "112336      116260       양정동 명심이족발   \n",
       "112337      116261       양정동 명심이족발   \n",
       "112338      116262       양정동 명심이족발   \n",
       "112339      116263       양정동 명심이족발   \n",
       "\n",
       "                                           review_content  rating        date  \\\n",
       "0       아기자기하고 빈티지한 분위기가 좋았어요 명란청양오일파스타랑 트러플버섯크림리조또 먹었...     NaN  2023-08-02   \n",
       "1       입구부터 이쁜 공간이 너무 많아서 좋았던 이곳 취향저격 제대로 당해서 안으로 들어왔...     NaN  2023-08-01   \n",
       "2       와    오랜만에 너무 만족스러운 식사하고 왔어여 매장 분위기도 너무 좋고 예쁘신 ...     NaN  2023-07-24   \n",
       "3       지난번에 너무 맛있게 먹고 이번에 재방문했어요   베이비치크 플레이트는 진짜 무조건...     NaN  2023-08-09   \n",
       "4       양 진짜 많고 너무 맛있어요 안에도 아기자기 앤티크하게 잘 꾸며져있고 감성도 맛도 ...     NaN  2023-07-05   \n",
       "...                                                   ...     ...         ...   \n",
       "112335                                               맛있어요     5.0  2020-12-19   \n",
       "112336                                       맛있고 양도 많았어요      5.0  2020-12-25   \n",
       "112337                                                좋아요     3.5  2020-10-29   \n",
       "112338                                               맛있어요     3.5  2019-12-15   \n",
       "112339                                                좋아요     NaN  2022-02-22   \n",
       "\n",
       "        visit register category  \\\n",
       "0           1      영수증       양식   \n",
       "1           1      영수증       양식   \n",
       "2           1      영수증       양식   \n",
       "3           1      영수증       양식   \n",
       "4           1      영수증       양식   \n",
       "...       ...      ...      ...   \n",
       "112335      1      영수증    족발,보쌈   \n",
       "112336      2      영수증    족발,보쌈   \n",
       "112337      1      영수증    족발,보쌈   \n",
       "112338      1      영수증    족발,보쌈   \n",
       "112339      1      영수증    족발,보쌈   \n",
       "\n",
       "                                       org_review_content  pred_proba  \\\n",
       "0       아기자기하고 빈티지한 분위기가 좋았어요ㅎㅎ 명란청양오일파스타랑 트러플버섯크림리조또 ...    0.997354   \n",
       "1       입구부터 이쁜 공간이 너무 많아서 좋았던 이곳 취향저격 제대로 당해서 안으로 들어왔...    0.997815   \n",
       "2       와..오랜만에 너무 만족스러운 식사하고 왔어여ㅠ 매장 분위기도 너무 좋고 예쁘신 사...    0.997788   \n",
       "3       지난번에 너무 맛있게 먹고 이번에 재방문했어요! 베이비치크 플레이트는 진짜 무조건 ...    0.997869   \n",
       "4       양 진짜 많고 너무 맛있어요ㅠㅠ 안에도 아기자기 앤티크하게 잘 꾸며져있고ㅠㅠㅠ 감성...    0.997817   \n",
       "...                                                   ...         ...   \n",
       "112335                                               맛있어요    0.905437   \n",
       "112336                                       맛있고 양도 많았어요!    0.985904   \n",
       "112337                                                좋아요    0.913858   \n",
       "112338                                               맛있어요    0.905437   \n",
       "112339                                                좋아요    0.913858   \n",
       "\n",
       "        pred_rating  \n",
       "0               1.0  \n",
       "1               1.0  \n",
       "2               1.0  \n",
       "3               1.0  \n",
       "4               1.0  \n",
       "...             ...  \n",
       "112335          1.0  \n",
       "112336          1.0  \n",
       "112337          1.0  \n",
       "112338          1.0  \n",
       "112339          1.0  \n",
       "\n",
       "[112340 rows x 11 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred 결과 dataframe에 추가\n",
    "\n",
    "df_input['pred_proba'] = preds.reshape(-1)\n",
    "df_input['pred_rating'] = np.nan\n",
    "df_input.loc[df_input['pred_proba'] > 0.5,'pred_rating'] = 1\n",
    "df_input.loc[df_input['pred_proba'] <= 0.5,'pred_rating'] = 0\n",
    "df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3dHmhdFgyd2"
   },
   "outputs": [],
   "source": [
    "# 결과 데이터프레임 저장\n",
    "\n",
    "df_input.to_excel(\"./data/230824_df_input_preped_with_pred_6차.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBpgDj14d8Xs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1xb4JE_cXkXTbNlyvR41yEWBNW79AVMre",
     "timestamp": 1685828976117
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
